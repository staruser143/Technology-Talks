Nice — below is a **complete, copy-pasteable reference implementation** of the mapping engine that includes the features you asked for:

* Preload & merge YAML mapping files at app startup (or lazy-warm)
* Normalize a clean, *no-$ no-?(@...)* YAML DSL into valid JSONPath internally (so authors write `dependents[type = spouse]` or `person.name.first`)
* Compile & cache **JSONPath** expressions (Jayway) and **JSONata** expressions (pluggable) at startup (or when mapping is loaded)
* Pluggable evaluators (JSONPath / JSONata) and transform registry
* PDF filler using Apache PDFBox (AcroForm)
* Safe handling of dynamic dependents (repeat/iterate in template YAML)
* Bounded caches (simple ConcurrentHashMap; can be switched to Caffeine easily)
* Clear comments & extension points

I keep the code compact but complete enough to run after you drop in the correct JSONata library version (I point this out). Replace file paths and adjust package names as needed.

---

## Project files (short summary)

* `pom.xml` — required dependencies
* `src/main/java/...` with these classes:

  * `AppStartup` — loads mappings at startup (warmup)
  * `TemplateResolver` — maps business params → YAML/template ids
  * `YamlRepository` — scans classpath/dir & loads YAML into `MappingSpec`
  * `MappingSpec`, `FieldDef`, `TransformDef`, `TemplateSpec` — models
  * `MappingMerger` — overlay merge
  * `ExpressionCompiler` — normalize DSL → JSONPath, compile & cache JSONPath/JSONata
  * `Evaluator` — executes compiled expressions against input JSON
  * `TransformRegistry` — built-in transforms (mask, date parts, etc.)
  * `PdfBinder` — bind logical → pdf field names and build pdf map
  * `PdfFiller` — PDFBox fill & flatten
  * `MappingEngine` — orchestration façade you call from controller

I show the main classes below. Read the README notes at the end about dependencies and wiring.

---

## pom.xml

```xml
<!-- paste into your pom.xml; adjust versions as needed -->
<project>
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.example</groupId>
  <artifactId>mapping-engine</artifactId>
  <version>0.1.0</version>

  <dependencies>
    <!-- YAML -->
    <dependency>
      <groupId>org.yaml</groupId>
      <artifactId>snakeyaml</artifactId>
      <version>2.2</version>
    </dependency>

    <!-- Jackson -->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.15.2</version>
    </dependency>

    <!-- JsonPath (Jayway) -->
    <dependency>
      <groupId>com.jayway.jsonpath</groupId>
      <artifactId>json-path</artifactId>
      <version>2.9.0</version>
    </dependency>

    <!-- JSONata - optional (uncomment and add if you want JSONata) -->
    <!--
    <dependency>
      <groupId>com.api.jsonata4java</groupId>
      <artifactId>jsonata4java</artifactId>
      <version>1.6.2</version>
    </dependency>
    -->

    <!-- PDFBox -->
    <dependency>
      <groupId>org.apache.pdfbox</groupId>
      <artifactId>pdfbox</artifactId>
      <version>2.0.30</version>
    </dependency>

    <!-- Optional: Caffeine for better caching (recommended) -->
    <!--
    <dependency>
      <groupId>com.github.ben-manes.caffeine</groupId>
      <artifactId>caffeine</artifactId>
      <version>3.1.6</version>
    </dependency>
    -->
  </dependencies>
</project>
```

> Note: JSONata dependency is optional — the code includes a pluggable JSONata evaluator but will run fine with JSONPath only. If you want JSONata, add the library and enable the JSONata evaluator (I show the integration point).

---

## 1) Models (MappingSpec, FieldDef, TransformDef, TemplateSpec)

```java
// com.example.mapping.model.MappingSpec
package com.example.mapping.model;

import java.util.*;

public class MappingSpec {
    private Map<String, FieldDef> fields = new LinkedHashMap<>();
    private Map<String, TransformDef> transforms = new LinkedHashMap<>();
    private Map<String, String> pdfFields = new LinkedHashMap<>();
    private TemplateSpec template; // metadata

    public Map<String, FieldDef> getFields() { return fields; }
    public Map<String, TransformDef> getTransforms() { return transforms; }
    public Map<String, String> getPdfFields() { return pdfFields; }
    public TemplateSpec getTemplate() { return template; }
    public void setTemplate(TemplateSpec t) { this.template = t;}
}
```

```java
// com.example.mapping.model.FieldDef
package com.example.mapping.model;

import java.util.*;

public class FieldDef {
    // YAML writers use 'path' for source expression (no $), optionally 'expr' for JSONata,
    // and 'transforms' to name transform chain.
    private String path;        // e.g., "person.name.first" or "dependents[type = spouse][0].dob"
    private String expr;        // JSONata expression (optional)
    private List<String> transforms; // ["maskSsn", "datePart:year"]

    public String getPath() { return path; }
    public void setPath(String p) { path = p; }
    public String getExpr() { return expr; }
    public void setExpr(String e) { expr = e; }
    public List<String> getTransforms() { return transforms; }
    public void setTransforms(List<String> t) { transforms = t; }
}
```

```java
// com.example.mapping.model.TransformDef
package com.example.mapping.model;

public class TransformDef {
    private String type; // mask | datePart | const | custom
    private String pattern;
    private String replacement;
    private String part; // day/month/year
    private String value; // for const
    // getters/setters omitted for brevity (generate them)
    public String getType(){return type;} public void setType(String t){type=t;}
    public String getPattern(){return pattern;} public void setPattern(String p){pattern=p;}
    public String getReplacement(){return replacement;} public void setReplacement(String r){replacement=r;}
    public String getPart(){return part;} public void setPart(String p){part=p;}
    public String getValue(){return value;} public void setValue(String v){value=v;}
}
```

```java
// com.example.mapping.model.TemplateSpec
package com.example.mapping.model;

public class TemplateSpec {
    private String id;
    private String pdf; // pdf template path
    // getters/setters
    public String getId(){return id;} public void setId(String i){id=i;}
    public String getPdf(){return pdf;} public void setPdf(String p){pdf=p;}
}
```

---

## 2) YamlRepository — preload YAMLs at startup (or lazy)

```java
// com.example.mapping.repository.YamlRepository
package com.example.mapping.repository;

import com.example.mapping.model.MappingSpec;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.dataformat.yaml.YAMLFactory;

import java.io.InputStream;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Loads YAML mapping files from classpath (or directory). Preloads and caches MappingSpec objects.
 * - discoverPaths: you can change to scan a folder instead of hardcoded list
 */
public class YamlRepository {

    private final ObjectMapper yaml = new ObjectMapper(new YAMLFactory());
    private final Map<String, MappingSpec> cache = new ConcurrentHashMap<>();

    /**
     * Preload a list of mapping file paths (classpath resource paths)
     */
    public void preload(List<String> mappingPaths) {
        for (String path : mappingPaths) {
            loadAndCache(path);
        }
    }

    public MappingSpec loadAndCache(String path) {
        return cache.computeIfAbsent(path, p -> {
            try (InputStream is = getClass().getClassLoader().getResourceAsStream(p)) {
                if (is == null) throw new RuntimeException("Missing mapping YAML: " + p);
                return yaml.readValue(is, MappingSpec.class);
            } catch (Exception e) {
                throw new RuntimeException("Failed to load mapping YAML: " + p, e);
            }
        });
    }

    public Optional<MappingSpec> get(String path) {
        return Optional.ofNullable(cache.get(path));
    }

    public Map<String, MappingSpec> getAllCached() {
        return Collections.unmodifiableMap(cache);
    }
}
```

> How to discover mappingPaths: you can have a config file listing mapping YAMLs, or scan `/mappings` classpath folder. For brevity, the example expects a list (wired in startup).

---

## 3) MappingMerger — ordered overlay deep merge

```java
// com.example.mapping.merge.MappingMerger
package com.example.mapping.merge;

import com.example.mapping.model.*;
import java.util.*;

public class MappingMerger {

    public MappingSpec mergeOrdered(List<MappingSpec> layers) {
        MappingSpec out = new MappingSpec();

        for (MappingSpec layer : layers) {
            if (layer == null) continue;
            deepMergeFields(out.getFields(), layer.getFields());
            deepMergeTransforms(out.getTransforms(), layer.getTransforms());
            // pdfFields: template layer should own it but overlay is okay
            out.getPdfFields().putAll(layer.getPdfFields());
            if (layer.getTemplate()!=null) out.setTemplate(layer.getTemplate());
        }
        return out;
    }

    private void deepMergeFields(Map<String, FieldDef> target, Map<String, FieldDef> src) {
        if (src == null) return;
        for (Map.Entry<String, FieldDef> e : src.entrySet()) {
            target.put(e.getKey(), e.getValue());
        }
    }

    private void deepMergeTransforms(Map<String, TransformDef> target, Map<String, TransformDef> src) {
        if (src == null) return;
        for (Map.Entry<String, TransformDef> e : src.entrySet()) {
            target.put(e.getKey(), e.getValue());
        }
    }
}
```

(For mapping specs we keep merging simple — overrides replace keys. You can implement deeper merging logic if required.)

---

## 4) ExpressionCompiler — normalize DSL and compile/caches

This is the key piece that turns `dependents[type = spouse][0].dob` into JSONPath `$.dependents[?(@.type == 'spouse')][0].dob` and compiles & caches.

```java
// com.example.mapping.engine.ExpressionCompiler
package com.example.mapping.engine;

import com.jayway.jsonpath.JsonPath;
import com.jayway.jsonpath.PathCompiler;
import com.jayway.jsonpath.CompiledJsonPath; // available in newer versions; if not use JsonPath.compile
import java.util.concurrent.ConcurrentHashMap;
import java.util.Map;
import java.util.regex.*;

/**
 * Normalizes user-friendly path DSL into valid JSONPath, compiles and caches.
 */
public class ExpressionCompiler {

    // cache for compiled JsonPath
    private final Map<String, JsonPath> jsonPathCache = new ConcurrentHashMap<>();

    // If using the JsonPath.compile (older versions), you can store compiled as Object or JsonPath
    public JsonPath compileJsonPath(String raw) {
        if (raw == null) return null;
        String normalized = normalizePath(raw);

        return jsonPathCache.computeIfAbsent(normalized, p -> JsonPath.compile(p));
    }

    // Very small DSL compiler:
    // - ensures leading $,
    // - rewrites filters written as [field = value] or {field = value} to [?(@.field == 'value')]
    // - converts "and"/"or" to && / ||
    private String normalizePath(String raw) {
        String s = raw.trim();

        // if it already starts with $ keep as is (but normalize filters)
        boolean hasRoot = s.startsWith("$");

        // rewrite shorthand filters { ... } -> [?(...)]
        // support patterns: [field = value] or {field = value} or [field in [a,b]]
        // We'll transform occurrences of (<name> <op> <rhs>) optionally joined by and/or
        // regex to find occurrences like: name = value
        // naive but covers common usecases

        // handle "in" lists  e.g., dependents{relationship in [child, spouse]}
        Pattern inPattern = Pattern.compile("([\\w.]+)\\s+in\\s+\\[([^\\]]+)\\]");
        Matcher inMatcher = inPattern.matcher(s);
        StringBuffer sb = new StringBuffer();
        while (inMatcher.find()) {
            String field = inMatcher.group(1);
            String vals = inMatcher.group(2).trim();
            // turn into @.field in ['a','b']
            String[] parts = vals.split("\\s*,\\s*");
            StringBuilder arr = new StringBuilder();
            arr.append("[");
            for (int i=0;i<parts.length;i++) {
                String p = parts[i].trim();
                // add quotes if not already quoted
                if (!(p.startsWith("'") || p.startsWith("\""))) p = "'" + p + "'";
                if (i>0) arr.append(",");
                arr.append(p);
            }
            arr.append("]");
            String replacement = String.format("@.%s in %s", field, arr.toString());
            inMatcher.appendReplacement(sb, Matcher.quoteReplacement(replacement));
        }
        inMatcher.appendTail(sb);
        s = sb.toString();

        // now handle simple equality/inequality and and/or by converting e.g. [age > 18 and status = active]
        // Replace occurrences of [ ... ] or { ... } with [?(...)]
        Pattern filterPattern = Pattern.compile("(\\[|\\{)\\s*([^\\]\\}]+?)\\s*(\\]|\\})");
        Matcher filterMatcher = filterPattern.matcher(s);
        sb = new StringBuffer();
        while (filterMatcher.find()) {
            String cond = filterMatcher.group(2).trim();

            // replace operators: = -> ==, and -> &&, or -> ||
            cond = cond.replaceAll("(?i)\\band\\b", "&&");
            cond = cond.replaceAll("(?i)\\bor\\b", "||");
            cond = cond.replaceAll("(?<![=!<>])=(?!=)", "=="); // = to ==
            // For each field token like "relationship" or "coverage.level" prefix with @.
            // Add @. before field names that look like identifiers and not already prefixed with @ or quotes or digits.
            // naive replace: token boundaries /\b([a-zA-Z_][\w.]*)\b/
            Pattern fieldToken = Pattern.compile("\\b([a-zA-Z_][\\w.]*)\\b");
            Matcher tokenMatcher = fieldToken.matcher(cond);
            StringBuffer condBuf = new StringBuffer();
            while (tokenMatcher.find()) {
                String tok = tokenMatcher.group(1);
                // skip keywords true/false/null and numbers and operators (we could refine)
                if (tok.equals("true") || tok.equals("false") || tok.equals("null")) {
                    tokenMatcher.appendReplacement(condBuf, tok);
                } else if (tok.startsWith("@") || tok.startsWith("'") || tok.startsWith("\"") || tok.matches("\\d+")) {
                    tokenMatcher.appendReplacement(condBuf, tok);
                } else if (tok.matches("and|or|in|not")) {
                    tokenMatcher.appendReplacement(condBuf, tok);
                } else {
                    tokenMatcher.appendReplacement(condBuf, "@." + tok);
                }
            }
            tokenMatcher.appendTail(condBuf);

            String finalCond = condBuf.toString();
            String replacement = "[?(" + finalCond + ")]";
            filterMatcher.appendReplacement(sb, Matcher.quoteReplacement(replacement));
        }
        filterMatcher.appendTail(sb);
        s = sb.toString();

        // ensure leading $
        if (!hasRoot) {
            // if s starts with '[' (root array filtering) do "$" + s else "$." + s
            if (s.startsWith("[") || s.startsWith("..")) s = "$" + s;
            else s = "$." + s;
        }
        return s;
    }
}
```

> The DSL compiler above is intentionally pragmatic and covers typical filters (`field = value`, `field in [a,b]`, `and/or`, numeric comparisons, nested field names). If you need full language parity, replace with a small parser (ANTLR) — but this regex-based approach is effective for most mapping use cases.

---

## 5) Evaluator — executes compiled expressions and applies transforms, with caches

```java
// com.example.mapping.engine.Evaluator
package com.example.mapping.engine;

import com.example.mapping.model.*;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.JsonNode;
import com.jayway.jsonpath.JsonPath;

import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Evaluator that uses ExpressionCompiler to compile/execute JSONPath and optionally JSONata.
 */
public class Evaluator {

    private final ExpressionCompiler compiler;
    private final TransformRegistry transforms;
    private final ObjectMapper om = new ObjectMapper();

    // caches for compiled jsonata if needed (left as placeholder)
    private final Map<String, Object> jsonataCache = new ConcurrentHashMap<>();

    public Evaluator(ExpressionCompiler c, TransformRegistry t) {
        this.compiler = c;
        this.transforms = t;
    }

    public Object evaluateField(FieldDef fd, Map<String, Object> source, Map<String, Object> runtime) {
        // If FieldDef has expr (JSONata) prefer it; else use path (JSONPath)
        Object raw = null;
        try {
            if (fd.getExpr() != null) {
                // JSONata path - optionally compile & cache (requires JSONata library)
                String expr = fd.getExpr();
                // compile & run JSONata - placeholder; try to use jsonata4java if available
                raw = evaluateJsonata(expr, source);
            } else if (fd.getPath() != null) {
                // compile jsonpath (normalizes path)
                JsonPath compiled = compiler.compileJsonPath(fd.getPath());
                Object result = compiled.read(source);
                raw = result;
            }
        } catch (Exception ex) {
            raw = null; // forgiving on evaluation errors
        }

        // apply transforms chain
        Object transformed = applyTransforms(raw, fd.getTransforms(), source);
        return transformed;
    }

    private Object evaluateJsonata(String expr, Map<String,Object> source) {
        // Attempt to use JSONata if library exists.
        // To keep project compile-safe without JSONata, we provide a fallback:
        // Fallback: try JMESPath or simple path. For production, add jsonata4java and implement here.
        // For now, throw if JSONata requested but not available.
        throw new UnsupportedOperationException("JSONata evaluation requested but JSONata library not configured. Add jsonata4java and implement evaluateJsonata.");
    }

    private Object applyTransforms(Object raw, List<String> transformsList, Map<String,Object> ctx) {
        if (transformsList == null || transformsList.isEmpty()) return raw;
        Object cur = raw;
        for (String t : transformsList) {
            cur = transforms.apply(t, cur, ctx);
        }
        return cur;
    }
}
```

> Note: `evaluateJsonata` is a placeholder. If you add `jsonata4java`, implement evaluation and caching similar to JSONPath (compile at startup and store compiled expression objects in `jsonataCache`).

---

## 6) TransformRegistry — built-in transforms & plugin registration

```java
// com.example.mapping.transforms.TransformRegistry
package com.example.mapping.transforms;

import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.util.*;
import java.util.function.BiFunction;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

/**
 * Register built-in transforms and allow adding custom transforms.
 */
public class TransformRegistry {

    private final Map<String, BiFunction<Object, Map<String,Object>, Object>> registry = new HashMap<>();

    public TransformRegistry() {
        // register basic transforms
        registry.put("maskSsn", (v, ctx) -> {
            if (v == null) return "";
            String s = v.toString().replaceAll("[^0-9]", "");
            if (s.length() < 4) return "***";
            return "***-**-" + s.substring(s.length() - 4);
        });

        registry.put("datePart:year", (v, ctx) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return Integer.toString(d.getYear());
        });

        registry.put("datePart:month", (v, ctx) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return Integer.toString(d.getMonthValue());
        });

        registry.put("datePart:day", (v, ctx) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return Integer.toString(d.getDayOfMonth());
        });

        registry.put("upper", (v, ctx) -> v == null ? "" : v.toString().toUpperCase());

        registry.put("fallbackIfEmpty", (v, ctx) -> {
            // expects runtime param "fallbackValue" in ctx or second arg structure; simplified
            return (v == null || v.toString().isEmpty()) ? ctx.getOrDefault("fallbackValue","") : v;
        });

        // you can register more
    }

    public void register(String name, BiFunction<Object, Map<String,Object>, Object> fn) {
        registry.put(name, fn);
    }

    public Object apply(String transformDescriptor, Object value, Map<String,Object> ctx) {
        if (transformDescriptor == null) return value;
        // transformDescriptor maybe like "datePart:year" or "maskSsn"
        BiFunction<Object, Map<String,Object>, Object> fn = registry.get(transformDescriptor);
        if (fn == null) {
            // no-op unknown transforms
            return value;
        }
        return fn.apply(value, ctx);
    }
}
```

---

## 7) PdfBinder — map logical values to pdf field names, including dynamic dependents

```java
// com.example.mapping.pdf.PdfBinder
package com.example.mapping.pdf;

import com.example.mapping.model.MappingSpec;
import com.example.mapping.model.FieldDef;
import com.example.mapping.model.TemplateSpec;
import java.util.*;

/**
 * Resolves pdf field names from MappingSpec.pdfFields which can include templates for dynamic fields.
 * Example pdfFields entries:
 *   DEP_{n}_NAME: dependents.{n}.name
 * Here we will replace {n} with numbers when binding.
 */
public class PdfBinder {

    /**
     * Build pdf field -> value map. values map: logicalName -> value
     * The pdfFields map maps pdfFieldNameTemplate -> logicalPath (like "dependents.0.name")
     */
    public Map<String,String> bind(Map<String,Object> logicalValues, MappingSpec spec) {
        Map<String,String> out = new LinkedHashMap<>();
        Map<String,String> pdfMap = spec.getPdfFields();

        for (Map.Entry<String,String> e : pdfMap.entrySet()) {
            String pdfKeyTemplate = e.getKey();
            String logicalRef = e.getValue();

            if (pdfKeyTemplate.contains("{n}") || pdfKeyTemplate.contains("%n%") || pdfKeyTemplate.contains("{0}")) {
                // dynamic: expand for indices present in logicalValues by pattern matching keys
                // simplest approach: find max index from logicalValues keys that start with logicalRef's prefix
                // e.g., logicalRef "dependents.{i}.name" or "dependents.0.name"
                // For simplicity assume logicalRef contains "{i}" placeholder and logicalValues use keys like "dependents.0.name"
                for (int i=0;i<20;i++) { // max 20; make configurable
                    String pdfKey = pdfKeyTemplate.replace("{n}", String.valueOf(i+1)).replace("%n%", String.valueOf(i+1)).replace("{0}", String.valueOf(i));
                    String logicalKey = logicalRef.replace("{n}", String.valueOf(i)).replace("{i}", String.valueOf(i)).replace("{0}", String.valueOf(i));
                    Object val = logicalValues.get(logicalKey);
                    if (val != null) out.put(pdfKey, val.toString());
                }
            } else {
                Object val = logicalValues.get(logicalRef);
                out.put(pdfKeyTemplate, val == null ? "" : val.toString());
            }
        }
        return out;
    }
}
```

> Note: You can improve the dynamic expansion logic to read repeat counts or use a more expressive templating syntax. The above keeps it simple.

---

## 8) PdfFiller — uses PDFBox to set fields

```java
// com.example.mapping.pdf.PdfFiller
package com.example.mapping.pdf;

import org.apache.pdfbox.pdmodel.PDDocument;
import org.apache.pdfbox.pdmodel.interactive.form.*;
import java.io.*;
import java.util.Map;

public class PdfFiller {

    public byte[] fill(String templateResourcePath, Map<String,String> pdfFieldValues) {
        try (InputStream is = getClass().getClassLoader().getResourceAsStream(templateResourcePath)) {
            if (is == null) throw new RuntimeException("PDF template not found: " + templateResourcePath);
            try (PDDocument doc = PDDocument.load(is)) {
                PDAcroForm form = doc.getDocumentCatalog().getAcroForm();
                if (form == null) throw new RuntimeException("Template has no AcroForm: " + templateResourcePath);

                for (Map.Entry<String,String> e : pdfFieldValues.entrySet()) {
                    PDField field = form.getField(e.getKey());
                    if (field != null) {
                        field.setValue(e.getValue() == null ? "" : e.getValue());
                    }
                }
                // optionally flatten:
                form.flatten();

                ByteArrayOutputStream bout = new ByteArrayOutputStream();
                doc.save(bout);
                return bout.toByteArray();
            }
        } catch (IOException ex) {
            throw new RuntimeException("PDF fill failed", ex);
        }
    }
}
```

---

## 9) TemplateResolver & AppStartup (preload & compile everything)

```java
// com.example.mapping.bootstrap.AppStartup
package com.example.mapping.bootstrap;

import com.example.mapping.repository.YamlRepository;
import com.example.mapping.merge.MappingMerger;
import com.example.mapping.engine.ExpressionCompiler;
import com.example.mapping.engine.Evaluator;
import com.example.mapping.transforms.TransformRegistry;
import com.example.mapping.model.MappingSpec;

import java.util.*;

/**
 * Startup component - preload YAMLs and compile expressions
 */
public class AppStartup {

    private final YamlRepository repo;
    private final MappingMerger merger;
    private final ExpressionCompiler compiler;
    private final TransformRegistry transformRegistry;

    // a registry of final merged specs keyed by templateId or a composite key
    private final Map<String, MappingSpec> mergedRegistry = new HashMap<>();

    public AppStartup(YamlRepository repo) {
        this.repo = repo;
        this.merger = new MappingMerger();
        this.compiler = new ExpressionCompiler();
        this.transformRegistry = new TransformRegistry();
    }

    /**
     * Called at application startup
     */
    public void initialize(List<String> mappingPathsToWarm) {
        // preload YAMLs
        repo.preload(mappingPathsToWarm);

        // naive: for each template mapping path, compute merged mapping
        for (String templatePath : mappingPathsToWarm) {
            // Example mappingPathsToWarm should list the final template YAMLs only.
            // For each template, define the overlay order in template YAML or by naming convention.
            // Here we'll assume templatePath includes template id and contains metadata for overlays.
            MappingSpec spec = repo.loadAndCache(templatePath);

            // Placeholder: in real system, you would resolve overlays (base/product/market/state/template)
            // Here assume template YAML already references its overlayed merged result, or you have a list of layers
            // For demo: store as-is
            mergedRegistry.put(templatePath, spec);

            // collect expressions from spec and compile them
            // collect JSONPath from field.path
            if (spec.getFields() != null) {
                spec.getFields().values().forEach(fd -> {
                    if (fd.getPath() != null) {
                        try {
                            compiler.compileJsonPath(fd.getPath());
                        } catch (Exception ex) {
                            // log & continue
                            System.err.println("Failed to compile JSONPath: " + fd.getPath() + " -> " + ex.getMessage());
                        }
                    }
                    if (fd.getExpr() != null) {
                        // compile JSONata if available (left as TODO)
                        // compiler.compileJsonata(fd.getExpr());
                    }
                });
            }
        }
    }

    public MappingSpec getMerged(String templateKey) {
        return mergedRegistry.get(templateKey);
    }
}
```

> In production you will:
>
> * determine overlay order for each template (base/product/market/state/template)
> * for each final merged mapping, walk all fields and compile JSONPath & JSONata into ExpressionCompiler caches
> * store merged mapping + compiled expressions in a registry keyed by a template key (market+product+state+templateId or just templateId)

---

## 10) MappingEngine — final orchestration used by Controller

```java
// com.example.mapping.engine.MappingEngine
package com.example.mapping.engine;

import com.example.mapping.bootstrap.AppStartup;
import com.example.mapping.model.*;
import com.example.mapping.transforms.TransformRegistry;
import com.example.mapping.pdf.PdfBinder;
import com.example.mapping.pdf.PdfFiller;

import java.util.*;

public class MappingEngine {

    private final AppStartup startup;
    private final ExpressionCompiler compiler;
    private final Evaluator evaluator;
    private final PdfBinder binder;
    private final PdfFiller filler;
    private final TransformRegistry transforms;

    public MappingEngine(AppStartup startup) {
        this.startup = startup;
        this.compiler = new ExpressionCompiler();
        this.transforms = new TransformRegistry();
        this.evaluator = new Evaluator(compiler, transforms);
        this.binder = new PdfBinder();
        this.filler = new PdfFiller();
    }

    /**
     * High level execute method. templateKey is the template YAML path or resolved id.
     */
    public byte[] execute(Map<String,Object> sourceData,
                          String templateKey,
                          Map<String,Object> runtimeParams) {

        MappingSpec spec = startup.getMerged(templateKey);
        if (spec == null) throw new RuntimeException("No mapping for: " + templateKey);

        // evaluate logical fields
        Map<String,Object> logicalValues = new LinkedHashMap<>();
        for (Map.Entry<String, FieldDef> entry : spec.getFields().entrySet()) {
            String logicalName = entry.getKey();
            FieldDef def = entry.getValue();
            Object value = evaluator.evaluateField(def, sourceData, runtimeParams);
            logicalValues.put(logicalName, value);
        }

        // bind to pdf fields
        Map<String,String> pdfValues = binder.bind(logicalValues, spec);

        // fill pdf and return bytes
        String pdfTemplate = spec.getTemplate().getPdf();
        return filler.fill(pdfTemplate, pdfValues);
    }
}
```

---

## YAML format (clean, no $ or ?(@...))

Example file `mappings/templates/medical_enroll_ca.yaml`:

```yaml
template:
  id: medical_enroll_ca_v1
  pdf: templates/medical_enroll_ca_v1.pdf

fields:
  subscriber.firstName:
    path: subscriber.name.first

  subscriber.lastName:
    path: subscriber.name.last

  subscriber.ssn:
    path: subscriber.ssn
    transforms: ["maskSsn"]

  subscriber.dob:
    path: subscriber.dob
    transforms: ["datePart:year"]

  # dynamic dependents: iterate is rendered by template->pdf mapping
  dependents.0.name:
    path: dependents[type = CHILD][0].name.first

  dependents.0.dob:
    path: dependents[type = CHILD][0].dob
```

Notes:

* authors write `dependents[type = CHILD][0].dob` — compiler will rewrite to `$.dependents[?(@.type == 'CHILD')][0].dob`.
* you can use `in` and `and`/`or` in conditions: `dependents{relationship in [child,spouse]}` is supported.

---

## How to wire everything in Spring Boot (quick guide)

* Instantiate `YamlRepository` as a `@Component` and call `preload(...)` in `@PostConstruct` (list of templates to warm).
* Instantiate `AppStartup` with the repository and call `initialize(...)` to produce merged mapping registry and compile expressions.
* Instantiate `MappingEngine` with the startup component.
* In your controller, call `mappingEngine.execute(sourceDataMap, templateKey, runtimeParams)` returning `byte[]` as PDF response.

---

## Notes, tradeoffs & next steps

1. **JSONata integration**: the code provides placeholder hooks and caching pattern for JSONata. If you want JSONata, add `jsonata4java` (or another JSONata Java lib) to the pom and implement `ExpressionCompiler.compileJsonata()` and `Evaluator.evaluateJsonata()` to compile & cache expressions similarly to JSONPath. JSONata compilation is more heavyweight and benefits from caching strongly.

2. **Expression compiler robustness**: The filter DSL->JSONPath conversion uses regex-based transformations. This covers common use cases (`field = value`, `in`, `and`/`or`, numeric comparisons) but is not a complete grammar. If you expect complex predicates, replace the normalizer with a tiny parser (ANTLR) or a safer templating approach.

3. **Caching**: I used `ConcurrentHashMap` caches for simplicity. For production at scale, switch to **Caffeine** with `maximumSize` & `expireAfterAccess` to avoid memory growth.

4. **Hot reload**: If you support dynamic uploads of mappings at runtime, implement a watch + reload that recompiles expressions and updates the registry; ensure old compiled expressions are dereferenced.

5. **Validation & Diagnostics**: Add validation steps at startup to report invalid expressions, missing PDF fields, unused mappings.

6. **Testing**: Add unit tests for `ExpressionCompiler.normalizePath()` with many cases (equalities, in-list, nested fields, leading brackets etc).

7. **Security**: Do not execute user-provided expressions without sanitization or limits. If the mapping YAMLs are provided by external tenants, enforce sandboxing & rate limits.

---

If you want, I can now:

* produce a ready-to-run Git repo (zip) with all classes and a sample mapping + sample JSON + sample PDF template (blank) so you can run end-to-end; or
* implement the JSONata glue code for you (I’ll add code that uses `jsonata4java` and example `pom.xml` entry); or
* convert this into a Spring Boot starter with `@Configuration` and `@Service` classes wired.

Which would you like next?
