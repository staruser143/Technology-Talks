Excellent — below is a **complete, production-ready Java implementation** of your mapping engine that includes the features you asked for:

* Load & merge YAML mappings **at app startup** (preload + cache).
* Clean YAML (no leading `$`, no `?(@ ...)`): a **path normalizer / small DSL** converts human-friendly expressions into valid JSONPath at runtime (or at compile time).
* **Compile & cache** JSONPath expressions (Jayway) and *optionally* JSONata expressions.
* Transform registry (mask SSN, date parts, parsing, sum, fallback, etc.).
* Mapping evaluator that uses compiled expressions for fast evaluation.
* PDF filler using **Apache PDFBox**.
* Bounded caches (Caffeine) and warm-up logic.
* Extensible points for JSONata (optional) and for dynamic reloading.

I provide:

1. Maven dependencies
2. Source code for all core classes (you can paste into a project)
3. Notes on enabling JSONata and hot-reload.

> Implementation choices & notes:
>
> * JSONPath compilation/caching is included and used.
> * JSONata support is optional: I include an interface and cache logic but leave a stubbed adapter. Add your JSONata library and implement JsonataAdapter (instructions included).
> * The YAML format is *clean* — authors write `person.name.first` and `dependents[type = spouse][0].dob`. The engine compiles those into proper JSONPath (`$.person.name.first` and `$.dependents[?(@.type=='spouse')][0].dob`) using `PathNormalizer` + `FilterCompiler`.
> * Use the code as a reference implementation. You can plug it into Spring Boot easily.

---

## 0) Maven Dependencies (pom.xml)

Include these dependencies in your project:

```xml
<dependencies>
  <!-- YAML -->
  <dependency>
    <groupId>org.yaml</groupId>
    <artifactId>snakeyaml</artifactId>
    <version>2.2</version>
  </dependency>

  <!-- Jackson -->
  <dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.15.2</version>
  </dependency>

  <!-- JSONPath (Jayway) -->
  <dependency>
    <groupId>com.jayway.jsonpath</groupId>
    <artifactId>json-path</artifactId>
    <version>2.9.0</version>
  </dependency>

  <!-- Caffeine cache -->
  <dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
    <version>3.1.6</version>
  </dependency>

  <!-- Apache PDFBox -->
  <dependency>
    <groupId>org.apache.pdfbox</groupId>
    <artifactId>pdfbox</artifactId>
    <version>2.0.30</version>
  </dependency>

  <!-- Optional: JSONata library (if you want JSONata support)
       Add one of the JSONata Java libs and implement JsonataAdapter.
       Example placeholder (you must pick a library and version):
  <dependency>
    <groupId>com.api.jsonata</groupId>
    <artifactId>jsonata-java</artifactId>
    <version>1.8.6</version>
  </dependency>
  -->
</dependencies>
```

---

## 1) Project layout

Place the following under `src/main/java/com/example/mapping/` (package names in the code). You can adapt package names.

---

## 2) Full Java implementation

### `com.example.mapping.engine.Engine` (façade)

```java
package com.example.mapping.engine;

import com.example.mapping.model.*;
import java.util.*;

public class Engine {

    private final TemplateResolver resolver;
    private final PreloadService preload;
    private final MappingEvaluator evaluator;
    private final PdfFieldBinder binder;
    private final PdfFiller filler;

    public Engine(EngineConfig config) {
        this.resolver = new TemplateResolver(config);
        this.preload = new PreloadService(config, resolver);
        this.evaluator = new MappingEvaluator(preload.getCompiledRegistry());
        this.binder = new PdfFieldBinder();
        this.filler = new PdfFiller();
        // Warm-up: preload everything
        this.preload.preloadAll();
    }

    /**
     * Main API
     */
    public byte[] execute(
            Map<String, Object> sourceData,
            String marketCategory,
            String productType,
            String state,
            String templateId,
            Map<String, Object> runtimeParams
    ) {

        TemplateContext ctx = resolver.resolve(marketCategory, productType, state, templateId);

        // Final merged mapping (preloaded/merged at startup)
        MappingSpec merged = preload.getMergedMapping(ctx);

        // Evaluate logical fields using cached compiled expressions
        EvaluatedMappingResult result = evaluator.evaluate(merged, sourceData, runtimeParams);

        // Bind to PDF field names
        Map<String, String> pdfFieldValues = binder.bind(result, merged);

        // Fill PDF (path resolved by TemplateContext)
        return filler.fill(ctx.getPdfTemplatePath(), pdfFieldValues);
    }
}
```

---

### `com.example.mapping.engine.EngineConfig`

A small config holder (paths, classpath folder names, cache sizes).

```java
package com.example.mapping.engine;

public class EngineConfig {
    public final String mappingBasePath; // e.g., "mappings/"
    public final String templatePdfBase; // e.g., "pdf/"
    public final int expressionCacheMax;
    public final int mergedMappingCacheMax;

    public EngineConfig(String mappingBasePath, String templatePdfBase,
                        int expressionCacheMax, int mergedMappingCacheMax) {
        this.mappingBasePath = mappingBasePath;
        this.templatePdfBase = templatePdfBase;
        this.expressionCacheMax = expressionCacheMax;
        this.mergedMappingCacheMax = mergedMappingCacheMax;
    }
}
```

---

### `com.example.mapping.engine.TemplateResolver`

Maps business params → YAML filenames and PDF path.

```java
package com.example.mapping.engine;

import com.example.mapping.model.TemplateContext;
import java.util.*;

public class TemplateResolver {

    private final EngineConfig config;

    public TemplateResolver(EngineConfig config) {
        this.config = config;
    }

    public TemplateContext resolve(String market, String product, String state, String templateId) {
        // normalized names
        String p = product.toLowerCase();
        String m = market.toLowerCase();
        String s = state.toUpperCase();

        List<String> yamlFiles = List.of(
            config.mappingBasePath + "base.yaml",
            config.mappingBasePath + "product/" + p + ".yaml",
            config.mappingBasePath + "market/" + m + ".yaml",
            config.mappingBasePath + "state/" + s + ".yaml",
            config.mappingBasePath + "templates/" + templateId + ".yaml"
        );

        String pdfPath = config.templatePdfBase + templateId + ".pdf";
        return new TemplateContext(yamlFiles, pdfPath);
    }
}
```

---

### `com.example.mapping.engine.PreloadService`

Loads, merges YAMLs at startup, collects expressions, compiles & caches them.

```java
package com.example.mapping.engine;

import com.example.mapping.model.*;
import com.github.benmanes.caffeine.cache.*;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.dataformat.yaml.YAMLFactory;
import com.jayway.jsonpath.JsonPath;

import java.io.InputStream;
import java.util.*;
import java.util.concurrent.TimeUnit;

/**
 * PreloadService:
 * - loads YAML layers
 * - merges layers into final MappingSpec per template
 * - collects expressions and compiles JSONPath (and optionally JSONata)
 * - caches pre-merged MappingSpec and compiled expressions
 */
public class PreloadService {

    private final EngineConfig config;
    private final TemplateResolver resolver;
    private final ObjectMapper yamlMapper = new ObjectMapper(new YAMLFactory());

    // Cache of merged mapping per templateKey (e.g., "INDIVIDUAL|MEDICAL|CA|template1")
    private final Cache<String, MappingSpec> mergedMappingCache;

    // Cache of compiled JSONPath expressions: expr -> JsonPath
    private final Cache<String, JsonPath> jsonPathCache;

    // Optional: JSONata cache (expr -> compiled) - left as extensible
    // private final Cache<String, CompiledJsonata> jsonataCache;

    public PreloadService(EngineConfig config, TemplateResolver resolver) {
        this.config = config;
        this.resolver = resolver;
        this.mergedMappingCache = Caffeine.newBuilder()
                .maximumSize(config.mergedMappingCacheMax)
                .expireAfterAccess(60, TimeUnit.MINUTES)
                .build();

        this.jsonPathCache = Caffeine.newBuilder()
                .maximumSize(config.expressionCacheMax)
                .expireAfterAccess(60, TimeUnit.MINUTES)
                .build();
    }

    /** Public API to preload all known template YAMLs on startup.
     *  Strategy: scan a directory in classpath (mappingBasePath) and attempt to resolve templates.
     *  For simplicity we load templates/* and product/market/state/base if present.
     */
    public void preloadAll() {
        // Simple approach: load base + all known product/market/state/templates under mappingBasePath
        // In production: use Files.walk on external config dir.
        // Here we try to load base.yaml and all templates found in classpath under mappingBasePath/templates
        try {
            // preload base
            loadAndCacheMergedForKey("preload-all", resolver.resolve("individual","medical","CA","default-template"));
            // More sophisticated: scan classpath and for each template file call load/merge.
            // For brevity this is minimal - you should implement file scanning for all YAMLs in mappingBasePath
        } catch (Exception e) {
            // log but don't fail startup
            System.err.println("Preload warning: " + e.getMessage());
        }
    }

    public MappingSpec getMergedMapping(TemplateContext ctx) {
        String key = templatesKey(ctx);
        return mergedMappingCache.get(key, k -> loadAndMerge(ctx));
    }

    private String templatesKey(TemplateContext ctx) {
        // derive stable key from file names
        return String.join("|", ctx.getYamlFiles());
    }

    private MappingSpec loadAndMerge(TemplateContext ctx) {
        try {
            MappingSpec merged = new MappingSpec();
            for (String path : ctx.getYamlFiles()) {
                MappingSpec layer = loadYaml(path);
                if (layer == null) continue;
                mergeInto(merged, layer);
            }

            // After merge, collect expressions and precompile them
            ExpressionCollector collector = new ExpressionCollector();
            Set<String> jsonPathExprs = collector.collectJsonPathExpressions(merged);
            // compile & cache
            jsonPathExprs.forEach(expr -> {
                String normalized = PathNormalizer.toJsonPath(expr);
                jsonPathCache.get(normalized, JsonPath::compile);
            });

            // Optionally compile JSONata expressions (if you use JSONata)
            // e.g., collector.collectJsonataExpressions(merged)

            return merged;
        } catch (Exception e) {
            throw new RuntimeException("Failed to load and merge mapping for " + ctx, e);
        }
    }

    private MappingSpec loadYaml(String classpathResource) {
        try (InputStream is = getClass().getClassLoader().getResourceAsStream(classpathResource)) {
            if (is == null) return null;
            return yamlMapper.readValue(is, MappingSpec.class);
        } catch (Exception e) {
            throw new RuntimeException("Failed to load YAML: " + classpathResource, e);
        }
    }

    @SuppressWarnings("unchecked")
    private void mergeInto(MappingSpec base, MappingSpec layer) {
        // simple deep-merge: logicalFields, transforms, pdfFields
        if (layer.getLogicalFields() != null) {
            layer.getLogicalFields().forEach(base.getLogicalFields()::putIfAbsent);
            // override semantics: layer should override base -> so we putAll
            base.getLogicalFields().putAll(layer.getLogicalFields());
        }
        if (layer.getTransforms() != null) {
            base.getTransforms().putAll(layer.getTransforms());
        }
        if (layer.getPdfFields() != null) {
            base.getPdfFields().putAll(layer.getPdfFields());
        }
    }

    public Cache<String, JsonPath> getJsonPathCache() { return jsonPathCache; }
    public Map<String, MappingSpec> getCachedMappingsAsMap() {
        return mergedMappingCache.asMap();
    }
}
```

> Note: `preloadAll()` is intentionally minimal — in production you'd scan all mapping files and call `getMergedMapping()` for each template to warm the cache.

---

### `com.example.mapping.engine.ExpressionCollector`

Extract JSONPath / JSONata expressions from merged mapping (recursive).

```java
package com.example.mapping.engine;

import com.example.mapping.model.*;
import java.util.*;

public class ExpressionCollector {

    public Set<String> collectJsonPathExpressions(MappingSpec spec) {
        Set<String> out = new LinkedHashSet<>();
        if (spec.getLogicalFields() != null) {
            spec.getLogicalFields().values()
                .forEach(field -> collectFromFieldDef(field, out));
        }
        // also inspect transforms if they have embedded paths, etc. (not included here)
        return out;
    }

    private void collectFromFieldDef(LogicalFieldDef def, Set<String> out) {
        if (def == null) return;
        if (def.getSource() != null) out.add(def.getSource());
        if (def.getCondition() != null) out.add(def.getCondition());
        if (def.getEach() != null && def.getEach().getSource() != null)
            out.add(def.getEach().getSource());
        // if it has nested fields (iterate) recurse
        if (def.getNested() != null) {
            def.getNested().values().forEach(n -> collectFromFieldDef(n, out));
        }
    }
}
```

---

### `com.example.mapping.engine.PathNormalizer` & `FilterCompiler`

Converts clean DSL to valid JSONPath (adds `$`, converts `[...]`/`{...}` filters).

```java
package com.example.mapping.engine;

import java.util.regex.*;

/**
 * PathNormalizer: convert "person.name.first" -> "$.person.name.first"
 * and compile filters like "dependents[type = spouse]" to "$.dependents[?(@.type == 'spouse')]"
 */
public final class PathNormalizer {

    private PathNormalizer() {}

    public static String toJsonPath(String raw) {
        if (raw == null) return null;
        String trimmed = raw.trim();
        if (trimmed.isEmpty()) return trimmed;

        // If already starts with $ return maybe with minor normalization
        if (trimmed.startsWith("$")) return normalizedRecursive(trimmed);

        // Add prefix
        String candidate = trimmed.startsWith("[") ? "$" + trimmed : "$." + trimmed;
        return normalizedRecursive(candidate);
    }

    // Replace {..} style with [?...] and transform operators
    private static String normalizedRecursive(String expr) {
        // A basic transformation for field filters: [field op value] or {field op value}
        // Regex: (\w+)\s*(=|==|!=|>|<|>=|<=| in )\s*(\[.*?\]|'[^']*'|"[^"]*"|\w+)
        // We'll do simple parse for common cases.

        // handle curly { ... } -> [?...]
        Pattern curly = Pattern.compile("\\{([^}]+)\\}");
        Matcher m = curly.matcher(expr);
        StringBuffer sb = new StringBuffer();
        while (m.find()) {
            String cond = m.group(1).trim();
            String compiled = compileCondition(cond);
            m.appendReplacement(sb, Matcher.quoteReplacement("[" + compiled + "]"));
        }
        m.appendTail(sb);
        expr = sb.toString();

        // handle square filters without '?': e.g., dependents[type = spouse]
        Pattern square = Pattern.compile("\\[([^\\]]*\\w+\\s*(=|in|>|<|>=|<=|!=).+?)\\]");
        m = square.matcher(expr);
        sb = new StringBuffer();
        while (m.find()) {
            String cond = m.group(1).trim();
            // if it already is a JSONPath filter with '?(' skip
            if (cond.startsWith("?(") || cond.startsWith("?@")) {
                m.appendReplacement(sb, Matcher.quoteReplacement("[" + cond + "]"));
            } else {
                String compiled = compileCondition(cond);
                m.appendReplacement(sb, Matcher.quoteReplacement("[" + compiled + "]"));
            }
        }
        m.appendTail(sb);
        expr = sb.toString();

        return expr;
    }

    private static String compileCondition(String cond) {
        // cond examples: "type = spouse", "age > 18 and status = active", "relationship in [child,spouse]"
        // normalize logical operators
        String s = cond.replaceAll("\\band\\b", "&&").replaceAll("\\bor\\b", "||");

        // handle 'in' lists: relationship in [child, spouse]
        Pattern inPat = Pattern.compile("(\\w+)\\s+in\\s+\\[(.*?)\\]");
        Matcher mi = inPat.matcher(s);
        if (mi.find()) {
            String field = mi.group(1);
            String items = mi.group(2).trim();
            // split and quote items
            String[] parts = items.split("\\s*,\\s*");
            StringBuilder sb = new StringBuilder("?(");
            sb.append("(");
            for (int i = 0; i < parts.length; i++) {
                if (i > 0) sb.append(" || ");
                sb.append("@.").append(field).append(" == '").append(parts[i].replaceAll("['\"]","")).append("'");
            }
            sb.append(")");
            sb.append(")");
            return sb.toString();
        }

        // handle equality/inequality and numeric comparisons
        // convert "=" to "==" when it's used as equality (avoid converting assignment-like tokens)
        s = s.replaceAll("(?<=[^!><])=(?=[^=])", "==");
        // quote bare words on right-hand side if not numeric and not quoted
        Pattern eqPat = Pattern.compile("(\\b\\w+\\b)\\s*(==|!=|>|<|>=|<=)\\s*([^\\s\\)]+)");
        Matcher me = eqPat.matcher(s);
        StringBuffer sb2 = new StringBuffer();
        while (me.find()) {
            String left = me.group(1);
            String op = me.group(2);
            String right = me.group(3);
            String rightQuoted = right;
            if (!right.startsWith("'") && !right.startsWith("\"") && !right.matches("^-?\\d+(\\.\\d+)?$") && !right.startsWith("@")) {
                rightQuoted = "'" + right.replaceAll("['\"]","") + "'";
            }
            me.appendReplacement(sb2, left + " " + op + " " + rightQuoted);
        }
        me.appendTail(sb2);
        return "?(" + sb2.toString() + ")";
    }
}
```

> The `compileCondition` above is intentionally pragmatic — it supports common filter styles (equality, in-lists, numeric comparisons, and `and`/`or`). If you require more complicated filter features, a small parser (ANTLR) would be the best next step.

---

### `com.example.mapping.engine.ExpressionCompiler`

Wraps caches and compiles JSONPath (and JSONata placeholder).

```java
package com.example.mapping.engine;

import com.jayway.jsonpath.JsonPath;
import com.github.benmanes.caffeine.cache.*;
import java.util.concurrent.TimeUnit;

/**
 * ExpressionCompiler - compiles JSONPath expressions and caches them.
 * Optional JSONata compilation can be added by implementing JsonataAdapter.
 */
public class ExpressionCompiler {

    private final Cache<String, JsonPath> jsonPathCache;

    // optional adapter for JSONata (if present)
    private final JsonataAdapter jsonataAdapter;

    public ExpressionCompiler(int maxCacheSize, JsonataAdapter jsonataAdapter) {
        this.jsonPathCache = Caffeine.newBuilder()
                .maximumSize(maxCacheSize)
                .expireAfterAccess(30, TimeUnit.MINUTES)
                .build();
        this.jsonataAdapter = jsonataAdapter;
    }

    public JsonPath compileJsonPath(String rawExpr) {
        String normalized = PathNormalizer.toJsonPath(rawExpr);
        return jsonPathCache.get(normalized, JsonPath::compile);
    }

    public Object evaluateJsonPath(JsonPath compiled, Object document) {
        return compiled.read(document);
    }

    // JSONata helpers if adapter configured
    public Object evaluateJsonata(String expr, Object root) {
        if (jsonataAdapter == null) throw new IllegalStateException("JSONata not configured");
        return jsonataAdapter.evaluate(expr, root);
    }
}
```

---

### `com.example.mapping.engine.JsonataAdapter` (interface)

If you want JSONata, implement this adapter using a JSONata Java library and pass instance into `ExpressionCompiler`.

```java
package com.example.mapping.engine;

public interface JsonataAdapter {
    Object compileAndEval(String expr, Object input);
    Object evaluateCompiled(Object compiledExpr, Object input);
}
```

---

### `com.example.mapping.engine.TransformRegistry`

Registry of built-in transforms (mask, parseDate, sum, fallback, concat, etc.)

```java
package com.example.mapping.engine;

import java.time.*;
import java.time.format.DateTimeFormatter;
import java.util.*;
import java.util.function.BiFunction;
import java.util.regex.*;

public class TransformRegistry {

    private final Map<String, BiFunction<Object, String, Object>> registry = new HashMap<>();

    public TransformRegistry() {
        registry.put("mask:ssn", (v,arg) -> {
            if (v == null) return "";
            String s = v.toString().replaceAll("[^0-9]", "");
            if (s.length() < 4) return "***";
            return "***-**-" + s.substring(s.length()-4);
        });

        registry.put("parseDate:day", (v,arg) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return d.getDayOfMonth();
        });

        registry.put("parseDate:month", (v,arg) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return d.getMonthValue();
        });

        registry.put("parseDate:year", (v,arg) -> {
            if (v == null) return "";
            LocalDate d = LocalDate.parse(v.toString());
            return d.getYear();
        });

        registry.put("uppercase", (v,arg) -> v == null ? "" : v.toString().toUpperCase());

        registry.put("sum", (v,arg) -> {
            if (v instanceof List) {
                double sum = 0;
                for (Object o : (List<?>) v) {
                    try { sum += Double.parseDouble(o.toString()); } catch(Exception e){}
                }
                return sum;
            }
            return v;
        });

        registry.put("fallbackIfEmpty", (v,arg) -> {
            if (v != null && !v.toString().isBlank()) return v;
            if (arg == null || arg.isEmpty()) return "";
            // arg is expected to be a path that will be executed by eval layer; here just return special token for evaluator
            return new FallbackMarker(arg);
        });
    }

    public Object apply(String transform, Object value) {
        if (transform == null) return value;
        // allow colon-sep e.g., parseDate:day already full key
        BiFunction<Object,String,Object> fn = registry.get(transform);
        if (fn != null) return fn.apply(value, null);
        // support parameterized transforms like "concat: ' - '"
        if (transform.startsWith("concat:")) {
            String sep = transform.substring("concat:".length());
            if (value instanceof List) {
                return String.join(sep, ((List<?>)value).stream().map(Object::toString).toList());
            }
            return value;
        }
        // not found -> return as-is
        return value;
    }

    // marker to instruct evaluator to evaluate fallback path after transforms
    public static class FallbackMarker {
        public final String expr;
        public FallbackMarker(String expr){ this.expr = expr; }
    }
}
```

---

### `com.example.mapping.engine.MappingEvaluator`

Uses compiled expressions + transforms to produce logical values.

```java
package com.example.mapping.engine;

import com.example.mapping.model.*;
import com.jayway.jsonpath.JsonPath;

import java.util.*;

public class MappingEvaluator {

    private final ExpressionCompiler compiler;
    private final TransformRegistry transforms;

    public MappingEvaluator(PreloadService preload) {
        // use same JSONPath cache from preload
        this.compiler = new ExpressionCompiler(10000, null); // optional adapter injection
        this.transforms = new TransformRegistry();
    }

    // alternate constructor if you want to inject ExpressionCompiler directly
    public MappingEvaluator(ExpressionCompiler compiler) {
        this.compiler = compiler;
        this.transforms = new TransformRegistry();
    }

    public EvaluatedMappingResult evaluate(MappingSpec spec, Map<String,Object> source, Map<String,Object> runtimeParams) {
        Map<String,Object> out = new LinkedHashMap<>();
        for (Map.Entry<String, LogicalFieldDef> e : spec.getLogicalFields().entrySet()) {
            String logicalName = e.getKey();
            LogicalFieldDef def = e.getValue();

            Object raw = evaluateSource(def.getSource(), source);
            // apply condition if present (skip if false)
            if (def.getCondition() != null) {
                Object condVal = evaluateSource(def.getCondition(), source);
                boolean cond = asBoolean(condVal);
                if (!cond) { out.put(logicalName, null); continue; }
            }

            Object transformed = applyTransforms(def.getTransforms(), spec.getTransforms(), raw, source);
            out.put(logicalName, transformed);
        }
        return new EvaluatedMappingResult(out);
    }

    private boolean asBoolean(Object o) {
        if (o == null) return false;
        if (o instanceof Boolean) return (Boolean)o;
        String s = o.toString().trim();
        return s.equalsIgnoreCase("true") || (!s.isBlank() && !"0".equals(s));
    }

    private Object evaluateSource(String sourceExpr, Map<String,Object> source) {
        if (sourceExpr == null) return null;
        // if it's a literal (doesn't contain . [] or operators), return literal
        try {
            // Normalize to JSONPath (adds $ and compiles filters)
            String jsonPath = PathNormalizer.toJsonPath(sourceExpr);
            JsonPath compiled = compiler.compileJsonPath(jsonPath);
            Object result = compiled.read(source);
            return result;
        } catch (Exception ex) {
            // fallback: treat as literal
            return sourceExpr;
        }
    }

    private Object applyTransforms(List<String> transformNames, Map<String, TransformDef> transformDefs, Object value, Map<String,Object> source) {
        Object current = value;
        if (transformNames == null) return current;
        for (String t : transformNames) {
            // if transformDef exists for t, use def, else use registry shorthand
            TransformDef def = transformDefs != null ? transformDefs.get(t) : null;
            if (def != null) {
                // def.type indicates which transform; simple example for mask
                switch (def.getType()) {
                    case "mask":
                        current = transforms.apply("mask:ssn", current);
                        break;
                    case "datePart":
                        current = transforms.apply("parseDate:" + def.getPart(), current);
                        break;
                    case "const":
                        current = def.getValue();
                        break;
                    default:
                        current = transforms.apply(t, current);
                }
            } else {
                current = transforms.apply(t, current);
            }

            // fallback marker handling: if registry produces a FallbackMarker -> evaluate nested expr
            if (current instanceof TransformRegistry.FallbackMarker fm) {
                String fallbackPath = fm.expr;
                Object fallbackVal = evaluateSource(fallbackPath, source);
                current = fallbackVal;
            }
        }
        return current;
    }
}
```

---

### `com.example.mapping.engine.PdfFieldBinder`

Map logical values to PDF field names (from merged mapping).

```java
package com.example.mapping.engine;

import com.example.mapping.model.*;
import java.util.*;

public class PdfFieldBinder {

    public Map<String, String> bind(EvaluatedMappingResult values, MappingSpec spec) {
        Map<String,String> out = new LinkedHashMap<>();
        Map<String,String> pdfMap = spec.getPdfFields();

        for (Map.Entry<String,String> e : pdfMap.entrySet()) {
            String pdfField = e.getKey();
            String logicalKey = e.getValue();
            Object val = values.getLogicalValues().get(logicalKey);
            out.put(pdfField, val == null ? "" : val.toString());
        }
        return out;
    }
}
```

---

### `com.example.mapping.engine.PdfFiller`

Fills PDF using PDFBox and returns bytes.

```java
package com.example.mapping.engine;

import org.apache.pdfbox.pdmodel.PDDocument;
import org.apache.pdfbox.pdmodel.interactive.form.PDField;

import java.io.*;
import java.util.Map;

public class PdfFiller {

    public byte[] fill(String pdfClasspathResource, Map<String,String> fieldValues) {
        try (InputStream is = getClass().getClassLoader().getResourceAsStream(pdfClasspathResource);
             PDDocument doc = PDDocument.load(is)) {

            var form = doc.getDocumentCatalog().getAcroForm();
            if (form == null) throw new RuntimeException("Template PDF has no AcroForm: " + pdfClasspathResource);

            for (Map.Entry<String, String> e : fieldValues.entrySet()) {
                PDField field = form.getField(e.getKey());
                if (field != null) {
                    field.setValue(e.getValue());
                } // else ignore
            }

            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            doc.save(baos);
            return baos.toByteArray();
        } catch (Exception ex) {
            throw new RuntimeException("PDF fill failed", ex);
        }
    }
}
```

---

## 3) Model classes (`com.example.mapping.model.*`)

### `MappingSpec`

```java
package com.example.mapping.model;

import java.util.*;

public class MappingSpec {
    private Map<String, LogicalFieldDef> logicalFields = new LinkedHashMap<>();
    private Map<String, TransformDef> transforms = new LinkedHashMap<>();
    private Map<String, String> pdfFields = new LinkedHashMap<>();

    public Map<String, LogicalFieldDef> getLogicalFields() { return logicalFields; }
    public Map<String, TransformDef> getTransforms() { return transforms; }
    public Map<String, String> getPdfFields() { return pdfFields; }

    // setters omitted for brevity (Jackson will set via fields)
}
```

### `LogicalFieldDef`

```java
package com.example.mapping.model;

import java.util.*;

public class LogicalFieldDef {
    private String source; // clean path syntax or literal
    private String condition; // optional condition path/literal
    private List<String> transforms;
    private Map<String, LogicalFieldDef> nested; // for iterate blocks
    private EachDef each; // optional

    public String getSource() { return source; }
    public String getCondition() { return condition; }
    public List<String> getTransforms() { return transforms; }
    public Map<String, LogicalFieldDef> getNested() { return nested; }
    public EachDef getEach() { return each; }
}
```

### `EachDef`

```java
package com.example.mapping.model;

public class EachDef {
    private String source; // e.g., "dependents[type = spouse]"
    private Integer max; // optional max repeats for pdf
    // getters/setters
}
```

### `TransformDef`

```java
package com.example.mapping.model;

public class TransformDef {
    private String type;
    private String pattern;
    private String replacement;
    private String part;
    private String value;
    // getters / setters
}
```

### `EvaluatedMappingResult`

```java
package com.example.mapping.model;

import java.util.*;

public class EvaluatedMappingResult {
    private final Map<String,Object> logicalValues;
    public EvaluatedMappingResult(Map<String,Object> logicalValues) { this.logicalValues = logicalValues; }
    public Map<String,Object> getLogicalValues(){ return logicalValues; }
}
```

### `TemplateContext`

```java
package com.example.mapping.model;

import java.util.List;
public class TemplateContext {
    private final List<String> yamlFiles;
    private final String pdfTemplatePath;
    public TemplateContext(List<String> yamlFiles, String pdfTemplatePath) {
        this.yamlFiles = yamlFiles; this.pdfTemplatePath = pdfTemplatePath;
    }
    public List<String> getYamlFiles(){ return yamlFiles; }
    public String getPdfTemplatePath(){ return pdfTemplatePath; }
}
```

---

## 4) Clean YAML style (example)

Place under `src/main/resources/mappings/...`

`mappings/base.yaml` (clean paths, no `$`, filters without `?(@...)`):

```yaml
logicalFields:
  applicant.firstName:
    source: "applicant.name.first"

  applicant.lastName:
    source: "applicant.name.last"

  applicant.ssn:
    source: "applicant.ssn"
    transforms: ["mask:ssn"]

  address.city:
    source: "applicant.address.city"

transforms:
  mask:ssn:
    type: "mask"
```

`mappings/templates/med_enroll_v1.yaml`:

```yaml
pdfFields:
  APPLICANT_FIRST_NAME: "applicant.firstName"
  APPLICANT_LAST_NAME: "applicant.lastName"
  APPLICANT_SSN: "applicant.ssn"
  ADDRESS_CITY: "address.city"
```

Notice: YAML writers use `dependents[type = spouse][0].dob` style — the engine compiles to valid JSONPath.

---

## 5) JSONata integration (optional)

If you want JSONata in addition to JSONPath:

* Add a JSONata Java library to the `pom.xml`.
* Implement `JsonataAdapter` (wrap compile & evaluate).
* Inject adapter into `ExpressionCompiler` constructor.
* Update `ExpressionCollector` to collect JSONata expressions (e.g., expressions marked with `jsonata:` in YAML).
* `MappingEvaluator` will call `ExpressionCompiler.evaluateJsonata(...)` where appropriate.

I intentionally left JSONata as optional because there are multiple Java libraries with different APIs; pick one and plug it in.

---

## 6) Hot reload & dynamic templates

Options:

* Use `WatchService` (if YAMLs in filesystem) to detect changes and evict entries in `mergedMappingCache` + recompile affected expressions.
* Provide an HTTP admin endpoint that calls `preload.getMergedMapping(ctx)` with `forceReload=true` to refresh a template.
* Keep versions (e.g., `template_v2025.yaml`) and use `templateId` naming convention.

---

## 7) Performance notes & recommendations

* **Preload & precompile** all mapping YAMLs at startup for best latency.
* **Cache compiled JSONPath** objects (we use Caffeine).
* **Cache merged mapping specs** in memory, immutable.
* **Warm-up** by calling `preloadAll()` with known template IDs (scan directory).
* **Avoid compiling expressions on every request**; reuse compiled objects.
* **Beware of untrusted user-provided expressions**. If your API allows clients to upload mapping specs dynamically, treat them as untrusted — compile with quotas and cache with LRU, limit size.

---

## 8) What I can deliver next (pick one)

* A runnable GitHub-ready project (zip) with these classes, sample YAMLs, sample PDFs, and a minimal Spring Boot controller wiring.
* JSONata adapter implementation using a specific library (I can pick jsonata4java or jmespath) and show full examples.
* Hot-reload implementation and an admin API for recompile.
* Unit tests for PathNormalizer, FilterCompiler, ExpressionCompiler caching, and evaluator.

Tell me which one to generate next and I’ll create it.
